# -*- coding: utf-8 -*-
"""Assignment_Task_6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17skdPlxcf8Uh-sQbu1zR1k5qH5hM5F_D

Assignment Task 6<br>Name: Niraj Kumar Yadav(22MCA0281)

Importing Required Library
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, classification_report
from sklearn.multiclass import OneVsRestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import LabelEncoder
import nltk

"""Loading the Daataset"""

data = pd.read_csv("/content/drive/MyDrive/DATASET_1/complaints.csv")

data.head()

"""#EDA"""

print("Dataset Info:")
print(data.info())

print("\nSummary Statistics:")
print(data.describe())

print("\nMissing Values:")
print(data.isnull().sum())

plt.figure(figsize=(10, 6))
sns.countplot(x='Product', data=data)
plt.title('Distribution of Products')
plt.xticks(rotation=90)
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(x='State', data=data)
plt.title('Distribution of States')
plt.xticks(rotation=90)
plt.show()

plt.figure(figsize=(6, 4))
sns.countplot(x='Consumer disputed?', data=data)
plt.title('Distribution of Consumer Disputed')
plt.show()

data['Complaint Length'] = data['Consumer complaint narrative'].apply(lambda x: len(str(x)))
plt.figure(figsize=(8, 5))
sns.histplot(data['Complaint Length'], bins=50)
plt.title('Distribution of Complaint Length')
plt.xlabel('Complaint Length')
plt.ylabel('Count')
plt.show()

plt.figure(figsize=(10, 8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

nltk.download('punkt')

nltk.download('stopwords')

nltk.download('wordnet')

"""Text Preprocessing"""

import string
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer


def preprocess_text(text):
    if pd.isna(text):
        text = ""

    text = text.lower()
    text = ''.join([char for char in text if char not in string.punctuation])
    tokens = nltk.word_tokenize(text)
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    processed_text = ' '.join(tokens)

    return processed_text

data['Consumer complaint narrative'] = data['Consumer complaint narrative'].apply(preprocess_text)
print(data['Consumer complaint narrative'].head())

data.head()

"""Train-Test Split, Model Building, Training and Evaluation"""

data['Consumer complaint narrative'] = data['Consumer complaint narrative'].str.lower()
tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')
X = tfidf_vectorizer.fit_transform(data['Consumer complaint narrative'])
y = data['Product']


# Train Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model Building- Multi model
model = OneVsRestClassifier(MultinomialNB())
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

print(classification_report(y_test, y_pred))

"""Model Prediction"""

new_complaints = data.head(1)
X_new = tfidf_vectorizer.transform(new_complaints['Consumer complaint narrative'])
predicted_categories = model.predict(X_new)

new_complaints['Predicted Product'] = predicted_categories

pd.set_option('display.max_colwidth', None)

new_complaints['Predicted Product']

"""Experiments with multple Machine Learning Models"""

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.multiclass import OneVsRestClassifier

# Logistic Regression
model_lr = OneVsRestClassifier(LogisticRegression(max_iter=1000))
model_lr.fit(X_train, y_train)

# Evaluate Model
y_pred_lr = model_lr.predict(X_test)
accuracy_lr = accuracy_score(y_test, y_pred_lr)
print("\nLogistic Regression Model:")
print(f'Accuracy: {accuracy_lr:.2f}')
print(classification_report(y_test, y_pred_lr))

# Random Forest Classifier
model_rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=100))
model_rf.fit(X_train, y_train)

# Evaluate Model
y_pred_rf = model_rf.predict(X_test)
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print("\nRandom Forest Classifier Model:")
print(f'Accuracy: {accuracy_rf:.2f}')
print(classification_report(y_test, y_pred_rf))

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from sklearn.metrics import accuracy_score, classification_report
from sklearn.multiclass import OneVsRestClassifier


max_words = 10000
tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(X_train)

X_train_rnn = tokenizer.texts_to_sequences(X_train)
X_test_rnn = tokenizer.texts_to_sequences(X_test)

max_sequence_length = 100

X_train_rnn = pad_sequences(X_train_rnn, maxlen=max_sequence_length)
X_test_rnn = pad_sequences(X_test_rnn, maxlen=max_sequence_length)

# Recurrent Neural Network - RNN
model_rnn = Sequential()
model_rnn.add(Embedding(max_words, 128, input_length=max_sequence_length))
model_rnn.add(LSTM(128))
model_rnn.add(Dense(64, activation='relu'))
model_rnn.add(Dropout(0.5))
model_rnn.add(Dense(num_classes, activation='softmax'))


model_rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model_rnn.fit(X_train_rnn, y_train, epochs=10, batch_size=32, validation_split=0.1)

# Evaluation
y_pred_rnn = model_rnn.predict(X_test_rnn)
y_pred_rnn = np.argmax(y_pred_rnn, axis=1)

accuracy_rnn = accuracy_score(y_test, y_pred_rnn)
print("Recurrent Neural Network (RNN) Model:")
print(f'Accuracy: {accuracy_rnn:.2f}')
print(classification_report(y_test, y_pred_rnn))